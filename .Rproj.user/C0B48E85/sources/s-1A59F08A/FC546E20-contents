---
title: "boosted_and_lasso"
author: "Ahlam Abuawad & Yanelli Nunez"
date: "5/2/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gbm)
library(tidyverse)
library(glmnet)
library(Matrix)
library(caret)
library(ggplot2)
```


```{r data}
data_lasso = read_csv("data_2015.csv") %>% select(everything(), -Humidity, -day_of_week) %>% drop_na

##visualizing variables
x = model.matrix(resp~., data_lasso)[,-(1:2)]
y = data_lasso$resp

featurePlot(x = x,
            y = y,
            between = list(x = 1, y = 1), 
            type = c("g", "p", "smooth"))
```


```{r train and test set}
set.seed(1)
##create train and test datasets
train_set = data_lasso[sample(nrow(data_lasso), 80),]
test_set = data_lasso[!row.names(data_lasso) %in% row.names(train_set),]

##create a matrix model for train and test set
x_train = model.matrix(resp ~., train_set)[,-(1:2)]
y_train = train_set$resp

x_test = model.matrix(resp ~., test_set)[,-(1:2)]
y_test = test_set$resp

```


```{r lasso}
set.seed(2)
lasso = glmnet(x_train, y_train, alpha = 1)
plot(lasso, xvar = "lambda")

##use cross-validation to find best lambda value
cv.lasso = cv.glmnet(x_train, y_train, alpha = 1)
plot(cv.lasso)
best_lambda = cv.lasso$lambda.min
best_lambda

##lasso model using best lambda value
lasso.mod = glmnet(x_train, y_train, alpha = 1, lambda = best_lambda)
coefficients_lasso = coef(lasso.mod)
coefficients_lasso

##prediction and MSE using train dataset
lasso.pred.train = predict(lasso.mod, s = best_lambda, newx = x_train)
lasso_MSE_train = mean((lasso.pred.train - y_train)^2)

##prediction and MSE using test dataset
lasso.pred = predict(lasso.mod, s = best_lambda, newx = x_test)
lasso_MSE_test = mean((lasso.pred - y_test)^2)

```


```{r include = FALSE}
data_2015 <- read_csv("data_2015.csv")
all_long <- read_csv("all_long.csv")
data_boost <- data_2015 %>% 
  select(-day_of_week, -Humidity, -date) %>% 
  as.data.frame() %>% 
  drop_na()
```


```{r include = FALSE}
set.seed(1)

## Creating training and test datasets
train_set = data_boost[sample(nrow(data_boost), 80),]
test_set = data_boost[!row.names(data_boost) %in% row.names(train_set),]

## Creating a matrix model for training and test sets
x_train = model.matrix(resp ~., train_set)[,-(1:2)]
y_train = train_set$resp

x_test = model.matrix(resp ~., test_set)[,-(1:2)]
y_test = test_set$resp
```


```{r boosted}
set.seed(8)

# Running boost with 100 iterations
boost.pm100 = gbm(resp ~ ., data = train_set, 
                distribution = "poisson", 
                n.trees = 100, 
                interaction.depth = 1, 
                shrinkage = 0.001) # depth should be 1 for additive model, # shrinkage is the learning rate and 0.001 is good for a small dataset and growing a lot of trees
boost.pm100
summary(boost.pm100) # ozone is extremely influential, followed by nickel and sulfur

pred.boost.train100 = predict(boost.pm100,
                         n.trees = boost.pm100$n.trees, 
                         type = "response")

pred.boost100 = predict(boost.pm100, 
                         newdata = test_set,
                         n.trees = boost.pm100$n.trees, 
                         type = "response") # this type returns counts for poisson distribution

pred.boost.round100 = round(pred.boost100)

# Finding the training set error (MSE)
boost_tmse100 = mean((pred.boost.train100 - train_set$resp)^2) 
boost_tmse100

# Finding the test set error (MSE)
boost_mse100 = mean((pred.boost100 - test_set$resp)^2) #contains true value from test data
boost_mse100

# Deviance score
dev_score100 = round(-log(dpois(test_set$resp, lambda = pred.boost100)), 2)

# Running boosted with 1000 iterations
boost.pm = gbm(resp ~ ., data = train_set, 
                distribution = "poisson", 
                n.trees = 1000, 
                interaction.depth = 1, 
                shrinkage = 0.001) # depth should be 1 for additive model, # shrinkage is the learning rate and 0.001 is good for a small dataset and growing a lot of trees
boost.pm
knitr::kable(summary(boost.pm)) # ozone is extremely influential, followed by nickel and sulfur

pred.boost.train = predict(boost.pm,
                         n.trees = boost.pm$n.trees, 
                         type = "response")

pred.boost = predict(boost.pm, 
                         newdata = test_set,
                         n.trees = boost.pm$n.trees, 
                         type = "response") # this type returns counts for poisson distribution

pred.boost.round = round(pred.boost)

# Finding the training set error (MSE)
boost_tmse = mean((pred.boost.train - train_set$resp)^2) 
boost_tmse

# Finding the test set error (MSE)
boost_mse = mean((pred.boost - test_set$resp)^2) #contains true value from test data
boost_mse

# Deviance score
dev_score = round(-log(dpois(test_set$resp, lambda = pred.boost)), 2)

# Table of first six deviance scores comparing true and predicted values from test set
compare = cbind(as.vector(test_set$resp), as.vector(pred.boost.round100), as.vector(dev_score100), as.vector(pred.boost.round), as.vector(dev_score))
rownames(compare) = colnames(test_set$resp); colnames(compare) = c("True", "Predicted for 100", "Deviance Score for 100", "Predicted for 1000", "Deviance Score for 1000")
knitr::kable(head(compare), align = "c")
```



## Comparing Boosted and Lasso

```{r}
# Table of MSE's
bl_compare = cbind(as.vector(boost_mse), as.vector(lasso_MSE_test))
rownames(bl_compare) = colnames(boost_mse); colnames(bl_compare) = c("Boosted Test MSE", "Lasso Test MSE")
knitr::kable(bl_compare, align = "c")
```

